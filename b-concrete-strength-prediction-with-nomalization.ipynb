{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Concrete Strength Prediction using Neural Networks\n",
    " This script builds a baseline regression model using Keras to predict concrete strength based on various ingredients and age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading concrete strength dataset...\")\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('data/concrete_data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\nDataset Information:\")\n",
    "print(f\"Number of samples: {df.shape[0]}\")\n",
    "print(f\"Number of features: {df.shape[1] - 1}\")  # Excluding the target variable\n",
    "print(\"\\nFeature names:\")\n",
    "for col in df.columns[:-1]:  # All columns except the last one\n",
    "    print(f\"- {col}\")\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPreparing data for model training...\")\n",
    "# Separate features (X) and target variable (y)\n",
    "# X contains all predictors: Cement, Blast Furnace Slag, Fly Ash, Water,\n",
    "# Superplasticizer, Coarse Aggregate, Fine Aggregate, and Age\n",
    "X = df.iloc[:, :-1].values\n",
    "# y contains the target variable: Concrete Strength\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1: Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization involves subtracting the mean and dividing by standard deviation\n",
    "# This puts all features on a similar scale, which helps neural networks learn better\n",
    "print(\"\\nNormalizing the data...\")\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit the scaler to the data and transform it\n",
    "# This calculates mean and standard deviation, then applies (x - mean) / std_dev\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Display information about the normalization\n",
    "print(\"\\nNormalization statistics:\")\n",
    "print(\"Feature means before normalization:\", np.mean(X, axis=0))\n",
    "print(\"Feature standard deviations before normalization:\", np.std(X, axis=0))\n",
    "print(\"Feature means after normalization:\", np.mean(X_normalized, axis=0))\n",
    "print(\"Feature standard deviations after normalization:\", np.std(X_normalized, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3-7: Repeat model training and evaluation 50 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRepeating model training and evaluation 50 times with different random splits...\")\n",
    "\n",
    "# Initialize a list to store the MSE values\n",
    "mse_list = []\n",
    "\n",
    "# Create a function to build and compile the model (to reuse in each iteration)\n",
    "def create_model(input_dim):\n",
    "    # Sequential model allows stacking layers in sequence\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add a hidden layer with 10 nodes and ReLU activation function as specified\n",
    "    # ReLU (Rectified Linear Unit) activation: f(x) = max(0, x)\n",
    "    # It introduces non-linearity and helps prevent the vanishing gradient problem\n",
    "    model.add(Dense(10, input_dim=input_dim, activation='relu'))\n",
    "    \n",
    "    # Add an output layer with a single node (for regression)\n",
    "    # No activation function means linear activation, appropriate for regression\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Compile the model with Adam optimizer and MSE loss\n",
    "    # Adam: Adaptive Moment Estimation, combines advantages of AdaGrad and RMSProp\n",
    "    # MSE: Measures the average squared difference between predictions and actual values\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Suppress verbose output during the loop\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress TensorFlow logging\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Run the process 50 times\n",
    "for i in range(50):\n",
    "    print(f\"\\nIteration {i+1}/50\")\n",
    "    \n",
    "    # Use scikit-learn's train_test_split with a different random state each time\n",
    "    # This ensures each iteration has a different train/test split\n",
    "    # test_size=0.3 holds 30% of the data for testing as specified\n",
    "    # random_state ensures reproducibility but varies each iteration\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_normalized, y, test_size=0.3, random_state=i\n",
    "    )\n",
    "    \n",
    "    print(f\"  Training: {X_train.shape[0]} samples, Testing: {X_test.shape[0]} samples\")\n",
    "    \n",
    "    # Create and compile the model\n",
    "    model = create_model(X_normalized.shape[1])\n",
    "    \n",
    "    # Train the model for 50 epochs as specified\n",
    "    # An epoch is one complete pass through the entire training dataset\n",
    "    # batch_size=32 means 32 samples are processed before the model is updated\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        verbose=0  # No output during training\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model by making predictions on the test set\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    \n",
    "    # Compute MSE using scikit-learn's mean_squared_error function\n",
    "    # MSE measures the average squared difference between predicted and actual values\n",
    "    # Lower MSE indicates better model performance\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list.append(mse)\n",
    "    print(f\"  Mean Squared Error: {mse:.4f}\")\n",
    "\n",
    "# Display statistics about the MSE values to understand model stability\n",
    "print(\"\\nMSE Statistics across 50 runs:\")\n",
    "print(f\"Mean MSE: {np.mean(mse_list):.4f}\")\n",
    "print(f\"Median MSE: {np.median(mse_list):.4f}\")\n",
    "print(f\"Min MSE: {np.min(mse_list):.4f}\")\n",
    "print(f\"Max MSE: {np.max(mse_list):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(mse_list):.4f}\")\n",
    "\n",
    "# Display all MSE values\n",
    "print(\"\\nList of all 50 MSE values:\")\n",
    "for i, mse in enumerate(mse_list):\n",
    "    print(f\"Run {i+1}: {mse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
